{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dde7260-fa6b-4ec6-8225-716c24c55ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting enhanced ADNI 3D CNN training...\n",
      "Labels shape: (2294, 12)\n",
      "Columns: ['Image Data ID', 'Subject', 'Group', 'Sex', 'Age', 'Visit', 'Modality', 'Description', 'Type', 'Acq Date', 'Format', 'Downloaded']\n",
      "Group distribution:\n",
      "Group\n",
      "MCI    1113\n",
      "CN      705\n",
      "AD      476\n",
      "Name: count, dtype: int64\n",
      "After filtering valid groups: 2294 samples\n",
      "Looking for files matching 2294 entries...\n",
      "Processed 0/2294 entries, found 1 matches so far...\n",
      "Processed 50/2294 entries, found 27 matches so far...\n",
      "Processed 100/2294 entries, found 50 matches so far...\n",
      "Processed 150/2294 entries, found 74 matches so far...\n",
      "Processed 200/2294 entries, found 106 matches so far...\n",
      "Processed 250/2294 entries, found 143 matches so far...\n",
      "Processed 300/2294 entries, found 176 matches so far...\n",
      "Processed 350/2294 entries, found 197 matches so far...\n",
      "Processed 400/2294 entries, found 222 matches so far...\n",
      "Processed 450/2294 entries, found 240 matches so far...\n",
      "Processed 500/2294 entries, found 273 matches so far...\n",
      "Processed 550/2294 entries, found 299 matches so far...\n",
      "Processed 600/2294 entries, found 321 matches so far...\n",
      "Processed 650/2294 entries, found 346 matches so far...\n",
      "Processed 700/2294 entries, found 372 matches so far...\n",
      "Processed 750/2294 entries, found 404 matches so far...\n",
      "Processed 800/2294 entries, found 436 matches so far...\n",
      "Processed 850/2294 entries, found 473 matches so far...\n",
      "Processed 900/2294 entries, found 500 matches so far...\n",
      "Processed 950/2294 entries, found 521 matches so far...\n",
      "Processed 1000/2294 entries, found 556 matches so far...\n",
      "Processed 1050/2294 entries, found 571 matches so far...\n",
      "Processed 1100/2294 entries, found 588 matches so far...\n",
      "Processed 1150/2294 entries, found 627 matches so far...\n",
      "Processed 1200/2294 entries, found 654 matches so far...\n",
      "Processed 1250/2294 entries, found 687 matches so far...\n",
      "Processed 1300/2294 entries, found 723 matches so far...\n",
      "Processed 1350/2294 entries, found 763 matches so far...\n",
      "Processed 1400/2294 entries, found 799 matches so far...\n",
      "Processed 1450/2294 entries, found 814 matches so far...\n",
      "Processed 1500/2294 entries, found 835 matches so far...\n",
      "Processed 1550/2294 entries, found 861 matches so far...\n",
      "Processed 1600/2294 entries, found 900 matches so far...\n",
      "Processed 1650/2294 entries, found 945 matches so far...\n",
      "Processed 1700/2294 entries, found 983 matches so far...\n",
      "Processed 1750/2294 entries, found 1004 matches so far...\n",
      "Processed 1800/2294 entries, found 1038 matches so far...\n",
      "Processed 1850/2294 entries, found 1082 matches so far...\n",
      "Processed 1900/2294 entries, found 1113 matches so far...\n",
      "Processed 1950/2294 entries, found 1146 matches so far...\n",
      "Processed 2000/2294 entries, found 1176 matches so far...\n",
      "Processed 2050/2294 entries, found 1210 matches so far...\n",
      "Processed 2100/2294 entries, found 1239 matches so far...\n",
      "Processed 2150/2294 entries, found 1258 matches so far...\n",
      "Processed 2200/2294 entries, found 1280 matches so far...\n",
      "Processed 2250/2294 entries, found 1306 matches so far...\n",
      "Found 1337 matching files\n",
      "Loaded 0/300 images...\n",
      "Loaded 50/300 images...\n",
      "Loaded 100/300 images...\n",
      "Loaded 150/300 images...\n",
      "Loaded 200/300 images...\n",
      "Loaded 250/300 images...\n",
      "Final data shape: (300, 64, 64, 64)\n",
      "Labels shape: (300, 3)\n",
      "Label mapping: {'AD': 0, 'CN': 1, 'MCI': 2}\n",
      "Class distribution: {'AD': 100, 'CN': 100, 'MCI': 100}\n",
      "\n",
      "=== Fold 1 ===\n",
      "Epoch 1/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 6s/step - accuracy: 0.3504 - loss: 2.4335 - val_accuracy: 0.3167 - val_loss: 1.7860 - learning_rate: 5.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 6s/step - accuracy: 0.3119 - loss: 2.2982 - val_accuracy: 0.3000 - val_loss: 1.9563 - learning_rate: 5.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 6s/step - accuracy: 0.3010 - loss: 2.2509 - val_accuracy: 0.3500 - val_loss: 1.7764 - learning_rate: 5.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 6s/step - accuracy: 0.3696 - loss: 2.0276 - val_accuracy: 0.3333 - val_loss: 3.1042 - learning_rate: 5.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 6s/step - accuracy: 0.3674 - loss: 1.9727 - val_accuracy: 0.2833 - val_loss: 2.5270 - learning_rate: 5.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 6s/step - accuracy: 0.3449 - loss: 2.1153 - val_accuracy: 0.2833 - val_loss: 2.3516 - learning_rate: 5.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.3457 - loss: 2.0079\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 6s/step - accuracy: 0.3458 - loss: 2.0077 - val_accuracy: 0.3167 - val_loss: 2.0844 - learning_rate: 5.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 5s/step - accuracy: 0.4016 - loss: 1.8479 - val_accuracy: 0.2833 - val_loss: 2.4797 - learning_rate: 1.5000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 5s/step - accuracy: 0.3092 - loss: 2.0004 - val_accuracy: 0.3667 - val_loss: 2.3810 - learning_rate: 1.5000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 6s/step - accuracy: 0.3448 - loss: 1.9992 - val_accuracy: 0.2667 - val_loss: 2.1511 - learning_rate: 1.5000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.3362 - loss: 1.9367\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 4.500000213738531e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 5s/step - accuracy: 0.3360 - loss: 1.9378 - val_accuracy: 0.3500 - val_loss: 2.3797 - learning_rate: 1.5000e-04\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Fold 1 Validation Accuracy: 0.3500\n",
      "\n",
      "=== Fold 2 ===\n",
      "Epoch 1/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 5s/step - accuracy: 0.3799 - loss: 2.2533 - val_accuracy: 0.3333 - val_loss: 2.0192 - learning_rate: 5.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 5s/step - accuracy: 0.3449 - loss: 2.2165 - val_accuracy: 0.3333 - val_loss: 2.5781 - learning_rate: 5.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 5s/step - accuracy: 0.3090 - loss: 2.3974 - val_accuracy: 0.3333 - val_loss: 4.7845 - learning_rate: 5.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 5s/step - accuracy: 0.4128 - loss: 2.1174 - val_accuracy: 0.3333 - val_loss: 4.7737 - learning_rate: 5.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.3390 - loss: 2.2102\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 5s/step - accuracy: 0.3396 - loss: 2.2086 - val_accuracy: 0.3333 - val_loss: 5.1510 - learning_rate: 5.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 5s/step - accuracy: 0.3944 - loss: 2.0961 - val_accuracy: 0.3333 - val_loss: 5.3391 - learning_rate: 1.5000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 5s/step - accuracy: 0.3718 - loss: 2.0848 - val_accuracy: 0.3333 - val_loss: 4.3769 - learning_rate: 1.5000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 5s/step - accuracy: 0.4306 - loss: 1.8555 - val_accuracy: 0.3333 - val_loss: 3.6080 - learning_rate: 1.5000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.3321 - loss: 2.0046\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 4.500000213738531e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 5s/step - accuracy: 0.3328 - loss: 2.0041 - val_accuracy: 0.3333 - val_loss: 2.9465 - learning_rate: 1.5000e-04\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Fold 2 Validation Accuracy: 0.3333\n",
      "\n",
      "=== Fold 3 ===\n",
      "Epoch 1/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 5s/step - accuracy: 0.4225 - loss: 2.3056 - val_accuracy: 0.3333 - val_loss: 1.8787 - learning_rate: 5.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 5s/step - accuracy: 0.3485 - loss: 2.2123 - val_accuracy: 0.3167 - val_loss: 1.7517 - learning_rate: 5.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 5s/step - accuracy: 0.4210 - loss: 2.1834 - val_accuracy: 0.3167 - val_loss: 1.8729 - learning_rate: 5.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 5s/step - accuracy: 0.4403 - loss: 2.1049 - val_accuracy: 0.3333 - val_loss: 2.2314 - learning_rate: 5.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 5s/step - accuracy: 0.3684 - loss: 2.0540 - val_accuracy: 0.3333 - val_loss: 2.6532 - learning_rate: 5.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.3371 - loss: 2.2250\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 5s/step - accuracy: 0.3370 - loss: 2.2238 - val_accuracy: 0.3333 - val_loss: 2.2918 - learning_rate: 5.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 5s/step - accuracy: 0.3475 - loss: 2.1003 - val_accuracy: 0.3000 - val_loss: 2.0066 - learning_rate: 1.5000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 6s/step - accuracy: 0.3616 - loss: 1.9910 - val_accuracy: 0.3333 - val_loss: 1.8389 - learning_rate: 1.5000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 5s/step - accuracy: 0.3736 - loss: 2.0230 - val_accuracy: 0.3500 - val_loss: 1.7632 - learning_rate: 1.5000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.3866 - loss: 1.8879\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 4.500000213738531e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 6s/step - accuracy: 0.3863 - loss: 1.8893 - val_accuracy: 0.3500 - val_loss: 1.7583 - learning_rate: 1.5000e-04\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Fold 3 Validation Accuracy: 0.3167\n",
      "\n",
      "=== Fold 4 ===\n",
      "Epoch 1/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 5s/step - accuracy: 0.3748 - loss: 2.4704 - val_accuracy: 0.3333 - val_loss: 1.8070 - learning_rate: 5.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 5s/step - accuracy: 0.3458 - loss: 2.4721 - val_accuracy: 0.3833 - val_loss: 1.7385 - learning_rate: 5.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 5s/step - accuracy: 0.3883 - loss: 2.1413 - val_accuracy: 0.3167 - val_loss: 1.7937 - learning_rate: 5.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 5s/step - accuracy: 0.3183 - loss: 2.1763 - val_accuracy: 0.3333 - val_loss: 3.6494 - learning_rate: 5.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 5s/step - accuracy: 0.3893 - loss: 2.1366 - val_accuracy: 0.3333 - val_loss: 3.9605 - learning_rate: 5.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.3869 - loss: 2.1363\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 5s/step - accuracy: 0.3862 - loss: 2.1367 - val_accuracy: 0.3167 - val_loss: 2.9976 - learning_rate: 5.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 5s/step - accuracy: 0.4075 - loss: 1.9477 - val_accuracy: 0.3333 - val_loss: 2.5284 - learning_rate: 1.5000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 6s/step - accuracy: 0.3169 - loss: 2.0652 - val_accuracy: 0.3000 - val_loss: 2.3935 - learning_rate: 1.5000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 5s/step - accuracy: 0.2970 - loss: 2.0658 - val_accuracy: 0.2833 - val_loss: 2.2794 - learning_rate: 1.5000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.4208 - loss: 1.9087\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 4.500000213738531e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 5s/step - accuracy: 0.4200 - loss: 1.9093 - val_accuracy: 0.2667 - val_loss: 1.9715 - learning_rate: 1.5000e-04\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Fold 4 Validation Accuracy: 0.3833\n",
      "\n",
      "=== Fold 5 ===\n",
      "Epoch 1/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 5s/step - accuracy: 0.3426 - loss: 2.4087 - val_accuracy: 0.3333 - val_loss: 2.0798 - learning_rate: 5.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 5s/step - accuracy: 0.3218 - loss: 2.2086 - val_accuracy: 0.3333 - val_loss: 3.0096 - learning_rate: 5.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 6s/step - accuracy: 0.3018 - loss: 2.3156 - val_accuracy: 0.3333 - val_loss: 4.1520 - learning_rate: 5.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 6s/step - accuracy: 0.3278 - loss: 2.1212 - val_accuracy: 0.3333 - val_loss: 3.0571 - learning_rate: 5.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.3612 - loss: 2.0128\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 5s/step - accuracy: 0.3618 - loss: 2.0130 - val_accuracy: 0.3333 - val_loss: 5.0582 - learning_rate: 5.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 5s/step - accuracy: 0.4308 - loss: 1.8687 - val_accuracy: 0.3333 - val_loss: 4.7515 - learning_rate: 1.5000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 5s/step - accuracy: 0.3641 - loss: 2.0792 - val_accuracy: 0.3333 - val_loss: 4.6033 - learning_rate: 1.5000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 5s/step - accuracy: 0.3867 - loss: 1.8474 - val_accuracy: 0.3333 - val_loss: 2.9264 - learning_rate: 1.5000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.3028 - loss: 2.0425\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 4.500000213738531e-05.\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 5s/step - accuracy: 0.3026 - loss: 2.0431 - val_accuracy: 0.3333 - val_loss: 2.6840 - learning_rate: 1.5000e-04\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Fold 5 Validation Accuracy: 0.3333\n",
      "\n",
      "Cross-validation results:\n",
      "Mean CV Accuracy: 0.3433 ± 0.0226\n",
      "\n",
      "Training completed successfully!\n",
      "Model saved as 'enhanced_adni_model.keras'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "class ADNIDataProcessor:\n",
    "    def __init__(self, data_dir, labels_path):\n",
    "        self.data_dir = data_dir\n",
    "        self.labels_path = labels_path\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        \n",
    "    def load_labels(self):\n",
    "        \"\"\"Load and process the ADNI labels CSV file\"\"\"\n",
    "        labels_df = pd.read_csv(self.labels_path)\n",
    "        print(f\"Labels shape: {labels_df.shape}\")\n",
    "        print(f\"Columns: {labels_df.columns.tolist()}\")\n",
    "        \n",
    "        # Check for the expected columns\n",
    "        required_cols = ['Image Data ID', 'Subject', 'Group']\n",
    "        for col in required_cols:\n",
    "            if col not in labels_df.columns:\n",
    "                print(f\"Warning: Column '{col}' not found in CSV\")\n",
    "        \n",
    "        print(f\"Group distribution:\\n{labels_df['Group'].value_counts()}\")\n",
    "        \n",
    "        # Filter only the rows with valid groups (CN, MCI, AD)\n",
    "        valid_groups = ['CN', 'MCI', 'AD']\n",
    "        labels_df = labels_df[labels_df['Group'].isin(valid_groups)]\n",
    "        print(f\"After filtering valid groups: {labels_df.shape[0]} samples\")\n",
    "        \n",
    "        return labels_df\n",
    "    \n",
    "    def preprocess_mri(self, nii_path, target_shape=(64, 64, 64)):\n",
    "        \"\"\"Enhanced MRI preprocessing with skull stripping simulation\"\"\"\n",
    "        try:\n",
    "            # Load NIfTI file\n",
    "            nii_img = nib.load(nii_path)\n",
    "            img_data = nii_img.get_fdata()\n",
    "            \n",
    "            # Simple brain extraction (remove background noise)\n",
    "            # Create a mask for brain tissue (non-zero values)\n",
    "            brain_mask = img_data > np.percentile(img_data[img_data > 0], 5)\n",
    "            img_data = img_data * brain_mask\n",
    "            \n",
    "            # Robust normalization using percentiles\n",
    "            p1, p99 = np.percentile(img_data[img_data > 0], [1, 99])\n",
    "            img_data = np.clip(img_data, p1, p99)\n",
    "            img_data = (img_data - p1) / (p99 - p1 + 1e-8)\n",
    "            \n",
    "            # Resize to target shape\n",
    "            zoom_factors = [target_shape[i] / img_data.shape[i] for i in range(3)]\n",
    "            img_resized = ndimage.zoom(img_data, zoom_factors, order=1)\n",
    "            \n",
    "            # Final normalization\n",
    "            img_resized = (img_resized - np.mean(img_resized)) / (np.std(img_resized) + 1e-8)\n",
    "            \n",
    "            return img_resized\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {nii_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def find_matching_files(self, labels_df):\n",
    "        \"\"\"Find MRI files that match the labels using Image Data ID\"\"\"\n",
    "        matched_data = []\n",
    "        \n",
    "        # Use the correct column names from the ADNI CSV\n",
    "        image_id_col = 'Image Data ID'\n",
    "        subject_col = 'Subject'\n",
    "        label_col = 'Group'\n",
    "        \n",
    "        print(f\"Looking for files matching {len(labels_df)} entries...\")\n",
    "        \n",
    "        for idx, row in labels_df.iterrows():\n",
    "            image_id = str(row[image_id_col]).strip()\n",
    "            subject_id = str(row[subject_col]).strip()\n",
    "            label = str(row[label_col]).strip()\n",
    "            \n",
    "            # Search for matching files in the directory structure\n",
    "            found = False\n",
    "            for root, dirs, files in os.walk(self.data_dir):\n",
    "                for file in files:\n",
    "                    if file.endswith('.nii') or file.endswith('.nii.gz'):\n",
    "                        # Check if the image ID is in the filename\n",
    "                        if image_id in file or f\"I{image_id}\" in file:\n",
    "                            file_path = os.path.join(root, file)\n",
    "                            matched_data.append({\n",
    "                                'file_path': file_path,\n",
    "                                'image_id': image_id,\n",
    "                                'subject_id': subject_id,\n",
    "                                'label': label\n",
    "                            })\n",
    "                            found = True\n",
    "                            break\n",
    "                \n",
    "                if found:\n",
    "                    break\n",
    "            \n",
    "            # Alternative search by subject ID if image ID not found\n",
    "            if not found:\n",
    "                for root, dirs, files in os.walk(self.data_dir):\n",
    "                    if subject_id in root:\n",
    "                        for file in files:\n",
    "                            if file.endswith('.nii') or file.endswith('.nii.gz'):\n",
    "                                file_path = os.path.join(root, file)\n",
    "                                matched_data.append({\n",
    "                                    'file_path': file_path,\n",
    "                                    'image_id': image_id,\n",
    "                                    'subject_id': subject_id,\n",
    "                                    'label': label\n",
    "                                })\n",
    "                                found = True\n",
    "                                break\n",
    "                    if found:\n",
    "                        break\n",
    "            \n",
    "            if idx % 50 == 0:\n",
    "                print(f\"Processed {idx}/{len(labels_df)} entries, found {len(matched_data)} matches so far...\")\n",
    "        \n",
    "        return matched_data\n",
    "    \n",
    "    def load_data(self, max_samples=None, target_shape=(64, 64, 64)):\n",
    "        \"\"\"Load and preprocess all data with balancing\"\"\"\n",
    "        # Load labels\n",
    "        labels_df = self.load_labels()\n",
    "        \n",
    "        # Find matching files\n",
    "        matched_data = self.find_matching_files(labels_df)\n",
    "        print(f\"Found {len(matched_data)} matching files\")\n",
    "        \n",
    "        # Balance classes if needed\n",
    "        if max_samples:\n",
    "            # Group by label and sample equally\n",
    "            matched_df = pd.DataFrame(matched_data)\n",
    "            balanced_data = []\n",
    "            \n",
    "            samples_per_class = max_samples // len(matched_df['label'].unique())\n",
    "            for label in matched_df['label'].unique():\n",
    "                label_data = matched_df[matched_df['label'] == label].sample(\n",
    "                    n=min(samples_per_class, len(matched_df[matched_df['label'] == label])),\n",
    "                    random_state=42\n",
    "                ).to_dict('records')\n",
    "                balanced_data.extend(label_data)\n",
    "            \n",
    "            matched_data = balanced_data\n",
    "        \n",
    "        # Load and preprocess images\n",
    "        X, y = [], []\n",
    "        \n",
    "        for i, data in enumerate(matched_data):\n",
    "            img = self.preprocess_mri(data['file_path'], target_shape)\n",
    "            if img is not None:\n",
    "                X.append(img)\n",
    "                y.append(data['label'])\n",
    "            \n",
    "            if i % 50 == 0:\n",
    "                print(f\"Loaded {i}/{len(matched_data)} images...\")\n",
    "        \n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        # Encode labels\n",
    "        y_encoded = self.label_encoder.fit_transform(y)\n",
    "        y_categorical = to_categorical(y_encoded)\n",
    "        \n",
    "        print(f\"Final data shape: {X.shape}\")\n",
    "        print(f\"Labels shape: {y_categorical.shape}\")\n",
    "        print(f\"Label mapping: {dict(zip(self.label_encoder.classes_, range(len(self.label_encoder.classes_))))}\")\n",
    "        \n",
    "        return X, y_categorical, self.label_encoder.classes_\n",
    "\n",
    "def create_improved_3d_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"3D CNN model with L2 regularization, Dropout, and BatchNorm\"\"\"\n",
    "    l2_reg = tf.keras.regularizers.l2(0.001)\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # First block\n",
    "    x = layers.Conv3D(32, (3, 3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv3D(32, (3, 3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling3D((2, 2, 2))(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "\n",
    "    # Second block\n",
    "    x = layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling3D((2, 2, 2))(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    # Third block\n",
    "    x = layers.Conv3D(128, (3, 3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv3D(128, (3, 3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling3D((2, 2, 2))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    # Global pooling\n",
    "    gap = layers.GlobalAveragePooling3D()(x)\n",
    "    gmp = layers.GlobalMaxPooling3D()(x)\n",
    "    x = layers.Concatenate()([gap, gmp])\n",
    "\n",
    "    # Dense layers\n",
    "    x = layers.Dense(256, activation='relu', kernel_regularizer=l2_reg)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "\n",
    "    x = layers.Dense(64, activation='relu', kernel_regularizer=l2_reg)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def create_data_augmentation():\n",
    "    \"\"\"Enhanced data augmentation for 3D medical images\"\"\"\n",
    "    def augment_3d(x, y):\n",
    "        # Convert to numpy if tensor\n",
    "        if hasattr(x, 'numpy'):\n",
    "            x = x.numpy()\n",
    "        \n",
    "        # Random rotation (small angles only for medical images)\n",
    "        if np.random.random() > 0.7:\n",
    "            angle = np.random.uniform(-5, 5)\n",
    "            axes = np.random.choice([(0, 1), (0, 2), (1, 2)])\n",
    "            x = ndimage.rotate(x, angle, axes=axes, reshape=False, order=1)\n",
    "        \n",
    "        # Random flip (only left-right for brain images)\n",
    "        if np.random.random() > 0.5:\n",
    "            x = np.flip(x, axis=0)\n",
    "        \n",
    "        # Gaussian noise\n",
    "        if np.random.random() > 0.8:\n",
    "            noise = np.random.normal(0, 0.05, x.shape)\n",
    "            x = x + noise\n",
    "        \n",
    "        # Intensity scaling\n",
    "        if np.random.random() > 0.8:\n",
    "            scale = np.random.uniform(0.9, 1.1)\n",
    "            x = x * scale\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    return augment_3d\n",
    "\n",
    "def train_model_with_kfold():\n",
    "    \"\"\"Improved training function with k-fold CV, augmentation, regularization\"\"\"\n",
    "    DATA_DIR = r\"C:\\Users\\hp\\Downloads\\ADNI1_Complete 1Yr 1.5T\\ADNI\"\n",
    "    LABELS_PATH = r\"C:\\Users\\hp\\Downloads\\ADNI_labels.csv\"\n",
    "    TARGET_SHAPE = (64, 64, 64)\n",
    "    BATCH_SIZE = 4\n",
    "    EPOCHS = 30\n",
    "\n",
    "    processor = ADNIDataProcessor(DATA_DIR, LABELS_PATH)\n",
    "    X, y, class_names = processor.load_data(target_shape=TARGET_SHAPE, max_samples=300)\n",
    "\n",
    "    if len(X) == 0:\n",
    "        print(\"No data loaded!\")\n",
    "        return None, None\n",
    "\n",
    "    X = X[..., np.newaxis]\n",
    "    y_labels = np.argmax(y, axis=1)\n",
    "    unique, counts = np.unique(y_labels, return_counts=True)\n",
    "    print(f\"Class distribution: {dict(zip([class_names[i] for i in unique], counts))}\")\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    fold_scores = []\n",
    "    augment_fn = create_data_augmentation()\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y_labels)):\n",
    "        print(f\"\\n=== Fold {fold + 1} ===\")\n",
    "\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = create_improved_3d_cnn_model(X_train_fold.shape[1:], len(class_names))\n",
    "\n",
    "        class_weights = {i: len(y_labels) / (len(unique) * count) for i, count in enumerate(counts)}\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizers.Adam(learning_rate=0.0005),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )b\n",
    "\n",
    "        callbacks_list = [\n",
    "            callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1),\n",
    "            callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=4, min_lr=1e-7, verbose=1)\n",
    "        ]\n",
    "\n",
    "        # Prepare augmented training dataset\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((X_train_fold, y_train_fold))\n",
    "        train_dataset = train_dataset.map(lambda x, y: tf.py_function(augment_fn, [x, y], [tf.float32, tf.float32]))\n",
    "        # Convert one-hot to class indices\n",
    "        y_train_indices = np.argmax(y_train_fold, axis=1)\n",
    "        y_val_indices = np.argmax(y_val_fold, axis=1)\n",
    "        \n",
    "        # Create datasets using integer labels\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((X_train_fold, y_train_indices))\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((X_val_fold, y_val_indices))\n",
    "        \n",
    "        # Optional: add your augmentation function if using\n",
    "        # train_dataset = train_dataset.map(lambda x, y: (tf.py_function(lambda a: augment_fn(a, y)[0], [x], tf.float32), y))\n",
    "        \n",
    "        train_dataset = train_dataset.shuffle(100).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "        val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "        history = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data=val_dataset,\n",
    "            epochs=EPOCHS,\n",
    "            callbacks=callbacks_list,\n",
    "            class_weight=class_weights,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        val_loss, val_accuracy = model.evaluate(val_dataset, verbose=0)\n",
    "        fold_scores.append(val_accuracy)\n",
    "        print(f\"Fold {fold + 1} Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        if fold == 0:\n",
    "            best_model = model\n",
    "            best_history = history\n",
    "\n",
    "    print(f\"\\nCross-validation results:\")\n",
    "    print(f\"Mean CV Accuracy: {np.mean(fold_scores):.4f} ± {np.std(fold_scores):.4f}\")\n",
    "\n",
    "    return best_model, best_history\n",
    "\n",
    "def evaluate_model_comprehensive(model, X_test, y_test, class_names):\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true_classes = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_true_classes, y_pred_classes, \n",
    "                              target_names=class_names, digits=4))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    print(\"\\nPer-class Accuracy:\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_acc = cm[i, i] / np.sum(cm[i, :]) if np.sum(cm[i, :]) > 0 else 0\n",
    "        print(f\"{class_name}: {class_acc:.4f}\")\n",
    "    \n",
    "    return y_pred, y_pred_classes\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run enhanced training\n",
    "    print(\"Starting enhanced ADNI 3D CNN training...\")\n",
    "    model, history = train_model_with_kfold()\n",
    "    \n",
    "    if model is not None:\n",
    "        print(\"\\nTraining completed successfully!\")\n",
    "        \n",
    "        # Save model in modern format\n",
    "        model.save('enhanced_adni_model.keras')\n",
    "        print(\"Model saved as 'enhanced_adni_model.keras'\")\n",
    "    else:\n",
    "        print(\"Training failed. Please check your data paths and setup.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
