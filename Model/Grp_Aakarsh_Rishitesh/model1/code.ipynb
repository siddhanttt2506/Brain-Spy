{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12296049,"sourceType":"datasetVersion","datasetId":7749966},{"sourceId":12306123,"sourceType":"datasetVersion","datasetId":7756772}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q monai nibabel scikit-learn\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T21:18:14.793287Z","iopub.execute_input":"2025-06-27T21:18:14.793918Z","iopub.status.idle":"2025-06-27T21:18:17.903975Z","shell.execute_reply.started":"2025-06-27T21:18:14.793893Z","shell.execute_reply":"2025-06-27T21:18:17.902925Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"import os                    \nimport pandas as pd           \nimport torch                  \nimport torch.nn as nn         \nimport torch.optim as optim   \nfrom torch.utils.data import Dataset, DataLoader, random_split \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T21:20:27.089695Z","iopub.execute_input":"2025-06-27T21:20:27.089978Z","iopub.status.idle":"2025-06-27T21:20:27.094074Z","shell.execute_reply.started":"2025-06-27T21:20:27.089956Z","shell.execute_reply":"2025-06-27T21:20:27.093305Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"import monai\nprint(\"MONAI version:\", monai.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T21:24:39.746067Z","iopub.execute_input":"2025-06-27T21:24:39.746767Z","iopub.status.idle":"2025-06-27T21:24:39.750613Z","shell.execute_reply.started":"2025-06-27T21:24:39.746745Z","shell.execute_reply":"2025-06-27T21:24:39.749872Z"}},"outputs":[{"name":"stdout","text":"MONAI version: 1.5.0\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"#MONAI\nfrom monai.transforms import (\n    Compose,           \n    LoadImaged,                 \n    ScaleIntensityd,    \n    ResizeWithPadOrCropd,\n    ToTensord,\n    Lambda           \n)\n\nfrom monai.data import Dataset\n\n# MONAI model \nfrom monai.networks.nets import resnet          \nfrom monai.networks.layers import Norm          \n\n# For accuracy, precision, recall, F1\nfrom sklearn.metrics import classification_report  \n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T21:28:25.623789Z","iopub.execute_input":"2025-06-27T21:28:25.624400Z","iopub.status.idle":"2025-06-27T21:28:25.628422Z","shell.execute_reply.started":"2025-06-27T21:28:25.624378Z","shell.execute_reply":"2025-06-27T21:28:25.627665Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"csv_path = \"/kaggle/input/labelled/mri_diagnosis_mapping.csv\" \ndf = pd.read_csv(csv_path)\n\nlabel_map = {\"AD\": 0, \"MCI\": 1, \"NC\": 2, \"CN\": 2}\n\ndf.columns = df.columns.str.strip() \ndf[\"Diagnosis\"] = df[\"Diagnosis\"].str.strip()  \n\n# Build list of dicts for MONAI\ndata_dicts = []\n\nfor _, row in df.iterrows():\n    img_path = row[\"MRI Path\"]\n    label = row[\"Diagnosis\"]\n    if label not in label_map:\n        continue\n    data_dicts.append({\n        \"image\": img_path,\n        \"label\": label_map[label]\n    })\n\nprint(f\"Loaded {len(data_dicts)} samples\")\nprint(\"Example sample:\\n\", data_dicts[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T21:15:18.166147Z","iopub.execute_input":"2025-06-27T21:15:18.166770Z","iopub.status.idle":"2025-06-27T21:15:18.205370Z","shell.execute_reply.started":"2025-06-27T21:15:18.166745Z","shell.execute_reply":"2025-06-27T21:15:18.204760Z"}},"outputs":[{"name":"stdout","text":"Loaded 460 samples\nExample sample:\n {'image': '/kaggle/input/preprocessed-output-zipped/preprocess_output_f/133_S_0913/MPR__GradWarp__B1_Correction__N3__Scaled_2/2007-07-18_15_09_17.0/I119636/ADNI_133_S_0913_MR_MPR__GradWarp__B1_Correction__N3__Scaled_2_Br_20081008095615528_S35319_I119636_final.nii', 'label': 1}\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"#MONAI Pipeline Transform\ntransforms = Compose([\n    LoadImaged(keys=[\"image\"]),  # Load NIfTI image\n    Lambda(func=lambda x: {\"image\": x[\"image\"][None, ...], \"label\": x[\"label\"]}),\n    ScaleIntensityd(keys=[\"image\"]),\n    ResizeWithPadOrCropd(keys=[\"image\"], spatial_size=(96, 96, 96)),\n    ToTensord(keys=[\"image\", \"label\"])\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T21:31:36.166514Z","iopub.execute_input":"2025-06-27T21:31:36.166812Z","iopub.status.idle":"2025-06-27T21:31:36.174633Z","shell.execute_reply.started":"2025-06-27T21:31:36.166791Z","shell.execute_reply":"2025-06-27T21:31:36.174072Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"from torch.utils.data import random_split, DataLoader\n\nfull_dataset = Dataset(data=data_dicts, transform=transforms)\n\ntorch.manual_seed(42)\n\n#80% train, 10% val, 10% test\ntotal_size = len(full_dataset)\ntrain_size = int(0.8 * total_size)\nval_size = int(0.1 * total_size)\ntest_size = total_size - train_size - val_size  # Remainder to make total exact\n\n\ntrain_dataset, val_dataset, test_dataset = random_split(\n    full_dataset,\n    [train_size, val_size, test_size]\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=2)\ntest_loader = DataLoader(test_dataset, batch_size=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T21:39:11.231045Z","iopub.execute_input":"2025-06-27T21:39:11.231367Z","iopub.status.idle":"2025-06-27T21:39:11.243084Z","shell.execute_reply.started":"2025-06-27T21:39:11.231345Z","shell.execute_reply":"2025-06-27T21:39:11.242415Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"from monai.networks.nets.resnet import resnet18  # Import ResNet18\n\n# AD, MCI, CN\nnum_classes = 3\n\n# 3D ResNet18 model\nmodel = resnet18(\n    spatial_dims=3,         # 3D convolutions\n    n_input_channels=1,     # MRI volumes are grayscale â†’ 1 channel\n    num_classes=num_classes # 3-way classification (AD/MCI/NC)\n)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T21:46:33.302922Z","iopub.execute_input":"2025-06-27T21:46:33.303273Z","iopub.status.idle":"2025-06-27T21:46:34.046554Z","shell.execute_reply.started":"2025-06-27T21:46:33.303245Z","shell.execute_reply":"2025-06-27T21:46:34.045984Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# loss function\ncriterion = nn.CrossEntropyLoss()\n\n# optimizer\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T22:13:40.622383Z","iopub.execute_input":"2025-06-27T22:13:40.622717Z","iopub.status.idle":"2025-06-27T22:13:40.627181Z","shell.execute_reply.started":"2025-06-27T22:13:40.622696Z","shell.execute_reply":"2025-06-27T22:13:40.626591Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"num_epochs = 10  \nbest_val_accuracy = 0.0\n\nfor epoch in range(num_epochs):\n    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n\n    # Training phase\n    model.train()\n    train_loss = 0.0\n    correct = 0\n    total = 0\n\n    for batch in train_loader:\n        images = batch[\"image\"].to(device)\n        labels = batch[\"label\"].to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item() * images.size(0)\n        preds = torch.argmax(outputs, dim=1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n\n    avg_train_loss = train_loss / total\n    train_acc = correct / total\n\n    print(f\"Train Loss: {avg_train_loss:.4f} | Train Accuracy: {train_acc:.4f}\")\n\n    # Validation phase\n    model.eval()\n    val_loss = 0.0\n    val_correct = 0\n    val_total = 0\n\n    with torch.no_grad():\n        for batch in val_loader:\n            images = batch[\"image\"].to(device)\n            labels = batch[\"label\"].to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            val_loss += loss.item() * images.size(0)\n            preds = torch.argmax(outputs, dim=1)\n            val_correct += (preds == labels).sum().item()\n            val_total += labels.size(0)\n\n    avg_val_loss = val_loss / val_total\n    val_acc = val_correct / val_total\n\n    print(f\"Val Loss: {avg_val_loss:.4f} | Val Accuracy: {val_acc:.4f}\")\n\n\n    # Save best model (optional)\n    if val_acc > best_val_accuracy:\n        best_val_accuracy = val_acc\n        torch.save(model.state_dict(), \"best_model.pth\")\n        print(\"Saved best model so far.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T22:13:45.314132Z","iopub.execute_input":"2025-06-27T22:13:45.314434Z","iopub.status.idle":"2025-06-27T22:32:00.970458Z","shell.execute_reply.started":"2025-06-27T22:13:45.314414Z","shell.execute_reply":"2025-06-27T22:32:00.969762Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/10\nTrain Loss: 0.8668 | Train Accuracy: 0.5951\nVal Loss: 1.6259 | Val Accuracy: 0.4130\nSaved best model so far.\n\nEpoch 2/10\nTrain Loss: 0.8330 | Train Accuracy: 0.6196\nVal Loss: 1.4117 | Val Accuracy: 0.3913\n\nEpoch 3/10\nTrain Loss: 0.7107 | Train Accuracy: 0.6929\nVal Loss: 1.3272 | Val Accuracy: 0.3696\n\nEpoch 4/10\nTrain Loss: 0.6280 | Train Accuracy: 0.7201\nVal Loss: 1.2502 | Val Accuracy: 0.4348\nSaved best model so far.\n\nEpoch 5/10\nTrain Loss: 0.4348 | Train Accuracy: 0.8370\nVal Loss: 1.1064 | Val Accuracy: 0.5870\nSaved best model so far.\n\nEpoch 6/10\nTrain Loss: 0.2926 | Train Accuracy: 0.8967\nVal Loss: 1.5468 | Val Accuracy: 0.3913\n\nEpoch 7/10\nTrain Loss: 0.1778 | Train Accuracy: 0.9457\nVal Loss: 1.1845 | Val Accuracy: 0.5870\n\nEpoch 8/10\nTrain Loss: 0.1523 | Train Accuracy: 0.9620\nVal Loss: 1.0990 | Val Accuracy: 0.6304\nSaved best model so far.\n\nEpoch 9/10\nTrain Loss: 0.0792 | Train Accuracy: 0.9755\nVal Loss: 1.1289 | Val Accuracy: 0.6304\n\nEpoch 10/10\nTrain Loss: 0.0309 | Train Accuracy: 0.9973\nVal Loss: 1.1462 | Val Accuracy: 0.5870\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"# Load best saved model\nmodel.load_state_dict(torch.load(\"best_model.pth\"))\nmodel.eval()\n\ntest_correct = 0\ntest_total = 0\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        images = batch[\"image\"].to(device)\n        labels = batch[\"label\"].to(device)\n\n        outputs = model(images)\n        preds = torch.argmax(outputs, dim=1)\n\n        test_correct += (preds == labels).sum().item()\n        test_total += labels.size(0)\n\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\ntest_acc = test_correct / test_total\nprint(f\"\\n Final Test Accuracy: {test_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T22:33:20.623694Z","iopub.execute_input":"2025-06-27T22:33:20.624277Z","iopub.status.idle":"2025-06-27T22:33:24.838081Z","shell.execute_reply.started":"2025-06-27T22:33:20.624249Z","shell.execute_reply":"2025-06-27T22:33:24.837261Z"}},"outputs":[{"name":"stdout","text":"\n Final Test Accuracy: 0.6087\n","output_type":"stream"}],"execution_count":42}]}